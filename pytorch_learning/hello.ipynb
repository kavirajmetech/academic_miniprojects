{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar=torch.tensor(3.12)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.119999885559082"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(3, 1, 1, 0))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc=torch.tensor([[[[]]],[[[]]],[[[]]]])\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], size=(3, 1, 1, 0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0867, 0.1786, 0.4535],\n",
       "        [0.2022, 0.4263, 0.8896],\n",
       "        [0.8046, 0.2642, 0.4097]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.rand(3,3)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5, 8],\n",
       "        [2, 6, 2],\n",
       "        [8, 7, 3]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.randint(0,10,(3,3))\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vasantha Raj\\AppData\\Local\\Temp\\ipykernel_21968\\1664205149.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  ra=torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.range(0,10)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000, 1.0000, 1.2000, 1.4000, 1.6000,\n",
       "        1.8000, 2.0000, 2.2000, 2.4000, 2.6000, 2.8000, 3.0000, 3.2000, 3.4000,\n",
       "        3.6000, 3.8000, 4.0000, 4.2000, 4.4000, 4.6000, 4.8000, 5.0000, 5.2000,\n",
       "        5.4000, 5.6000, 5.8000, 6.0000, 6.2000, 6.4000, 6.6000, 6.8000, 7.0000,\n",
       "        7.2000, 7.4000, 7.6000, 7.8000, 8.0000, 8.2000, 8.4000, 8.6000, 8.8000,\n",
       "        9.0000, 9.2000, 9.4000, 9.6000, 9.8000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.arange(0,10,0.2)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.5263,  1.0526,  1.5789,  2.1053,  2.6316,  3.1579,  3.6842,\n",
       "         4.2105,  4.7368,  5.2632,  5.7895,  6.3158,  6.8421,  7.3684,  7.8947,\n",
       "         8.4211,  8.9474,  9.4737, 10.0000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.linspace(0,10,20)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.zeros(3,3)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.ones(3,3)\n",
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra=torch.eye(3,dtype=torch.float32)\n",
    "ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32 bit - torch.float32|torch.float,torch.FloatTensor,torch.cuda.FloatTensor\n",
    "\n",
    "64 bit - torch.float64|torch.double,torch.DoubleTensor,torch.cuda.DoubleTensor\n",
    "\n",
    "16 bit torch.float16|torch.half,torch.HalfTensor,torch.cuda.HalfTensor\n",
    "\n",
    "torch.complex32\n",
    "\n",
    "dtype\n",
    "\n",
    "device\n",
    "\n",
    "requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attribute problems of tensor\n",
    "\n",
    "tensor not right datatype tensor.dtype\n",
    "\n",
    "tensor not right shape tensor.shape\n",
    "\n",
    "tensor not right device tensor.device\n",
    "\n",
    "Tensor operations include :\n",
    "\n",
    "Addition, subtraction, multiplication (element wise), Division, Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ra=torch.rand(3,3 ,dtype=torch.cuda.FloatStorage)\n",
    "# ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0, 10, 20],\n",
       "         [ 0, 10, 20],\n",
       "         [ 5, 15, 25]],\n",
       "\n",
       "        [[10, 20, 40],\n",
       "         [10, 20, 40],\n",
       "         [15, 25, 45]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.tensor([[[10,20,30]],[[20,30,50]]])\n",
    "t1=torch.tensor([[-10],[-10],[-5]])\n",
    "t+t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two main ways of performing multiplication in neural networks and deep learning\n",
    "\n",
    "element wise multiplication\n",
    "\n",
    "matrix dot product torch.matmul or @ (operator for matric multiplication)\n",
    "\n",
    "    inner dimensions should satisfy the multiplication condition\n",
    "\n",
    "    resulting matrix has the shape of the outer dimension\n",
    "\n",
    "tensor aggregation min, max, mean and sum (torch.aggmethod(tensor) or tensor.aggmethod())\n",
    "\n",
    "positional min and max \n",
    "\n",
    "tensor.argmin(),tensor.argmax()\n",
    "\n",
    "indexing, reshaping, stacking, squeezing and unsqueesing\n",
    "\n",
    "* reshaping - reshapes an input tensor to a defined shape\n",
    "* view - return a view of an input tensor of certain shape but keep the same memory as the original  tensor\n",
    "* stacking - concatenating a sequence of tensors along a new dimension.\n",
    "* squeeze - remove all '1' dimensions from a tensor\n",
    "* unsqueeze - add a 1 dimension to a target tensor\n",
    "* permute - return a view of the input with dimensions permuted in a certain way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape,t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 766 ms\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tensor.reshape(shape)\n",
    "* tensor.view(shape)\n",
    "* tensor.stack([tensors],dim=0 or 1)\n",
    "* torch.sqeeze(tensor) or tensor.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra.permute(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ra.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tensors and numpy nd arrays\n",
    "\n",
    "pytorch has functionality to interact with it.\n",
    "\n",
    "* Data in numpy what in pytorch -> torch.from_numpy(ndarray)\n",
    "* pytorch tensor -> numpy -> torch.Tensor.numpy()\n",
    "\n",
    "Pytorch Reproducibility (Taking the random out of random)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "**Running tensors and pytorch object on GPU**\n",
    "\n",
    "\n",
    "device agnostic code of argparse  https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
    "\n",
    "\n",
    "GPU to CPU and vice vers - learn!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu118'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch model building essentials\n",
    "\n",
    "* torch.nn - contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
    "* torch.nn.Parameter - what parameters should our model try and learn, often a pytorch layer from torch.nn will set these for us\n",
    "* torch.nn.Module - the base class for all neural network modules, if you subclass it, you should overwrite forward()\n",
    "* forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch.org/tutorials/beginner/ptcheat.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neural network api libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torch.autograd as autograd \n",
    "from torch import Tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are two versions of the exporter\n",
    "\n",
    "torchdynamo-based onnx exporter\n",
    "    \n",
    "torchscript-based onnx exporter\n",
    "\n",
    "FX grpah - tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2527913872.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[45], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    torch.onnx.export(model,dummy data,xxxx.proto) #exports as onnx formatted model using a trained model, dummy data and the desired file name\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model,dummy data,xxxx.proto) #exports as onnx formatted model using a trained model, dummy data and the desired file name\n",
    "\n",
    "model=torch.onnx.load('alexnet.proto') #load an onnx model\n",
    "torch.onnx.checker.check_model(model) #check that the model is well formed\n",
    "\n",
    "\n",
    "torch.onnx.helper.printable_graph(model.graph) #print a human readable representaton of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mod=Linear()\n",
    "        self.weight=nn.Parameter(torch.randn(1,requires_grad=True))\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        return self.weight*self.mod.forward()\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.we=nn.Parameter(torch.randn(1,requires_grad=True) )\n",
    "    def forward(self):\n",
    "        return self.we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearModel(\n",
       "  (mod): Linear()\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1.8969], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.4213], requires_grad=True)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "difference modes in pytorch\n",
    "\n",
    "with torch.inference_mode()\n",
    "\n",
    "with torch.no_grad()\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "set up loss function and optimizer\n",
    "\n",
    "* buiilding a training loop\n",
    "\n",
    "couple of things we need in a training loop\n",
    "\n",
    "oop through the data\n",
    "\n",
    "forward pass to make predictions on data\n",
    "\n",
    "calculate the loss \n",
    "\n",
    "optimizer zero grad\n",
    "\n",
    "loss backward\n",
    "\n",
    "optimizer step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can define our own way of loss functions other than torch implemented functions, but the loss function should be differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are three main methods we should about for saving and loading models in pytorch\n",
    "\n",
    "1. torch.save() - allows us to save a pytorch object in python's pickle format\n",
    "2. torch.load() - allows us to load a saved pytorch object\n",
    "3. torch.nn.Module.load_state_dict() - allows us to load a model's saved state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
