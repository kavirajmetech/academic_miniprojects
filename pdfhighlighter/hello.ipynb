{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vasantha\n",
      "[nltk_data]     Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Selected PDF: C:/Users/Vasantha Raj/Desktop/Road Pothole Detection Using YoloV8-1.pdf\n",
      "an intensive project on road damage detection   using yolov8 and additive optimization  techiniques along with the survey on various   n r gladiss merlin  department of ads  rmk engineering college chennai   kaviyarasu s  department of ads  rmk engineering college chennai india   keshavardhan d r  department of ads  rmk engineering college chennai india   ashraf deen a  department of ads  rmk engineering college chennai india   jeyanth s  department of ads  rmk engineering college chennai india     deep learning has gained significant traction in the  realm of computer technology with road damage detection  technology emerging as a crucial component for road maintenance  and harmony in traffic timely identification of road defects such  as potholes and cracks are imperative for ensuring road safety  facilitating prompt repairs and ensuring the quality infrastructure  for public consequently road damage detection algorithms  leveraging  deep learning  methodologies  have  garnered  considerable interest yolov8 stands out as an advanced image  recognition detection renowned for its swift detection speed and  commendable accuracy nonetheless there remains ample  opportunity for enhancing its performance in road defect  detection the capability to detect damage across multiple scales  and capture spatial structures is not yet fully optimized to address  this this paper proposes some key enhancements to augment the  accuracy of road damage detection using yolov8 firstly by  applying various augmentation techniques such as rotation  flipping and etc adding noise to the training dataset to diversify  the cases to be handled by introducing the nonlinear spatial  pyramid pooling fast nsppf module 1 so these module  facilitates a more comprehensive capture of intricate features  within  road  damage  areas  leveraging  nonlinear  transformations and rapid pyramid operations it enhances the  models ability to sense and detect damage across varying scales  secondly by devise a fusion of the coordconv and sk attention  modules  1 the coordconv module integrates coordinate  information with features 1 enriching the representation with  spatial context additionally the sk attention module learns  relationships between public and private features bolstering the  models capacity to identify damages at multilevel scales the  synergistic integration of these modules enables a more nuanced  understanding of road damage spatial structures and contextual  information finally experimental evaluations conducted on the  rdd2020 dataset rdd2022 dataset custom dataset collected  from various resources and labelled with expert advice  underscore the efficacy of our proposed model compared to the  basic model our enhanced algorithm yields a notable increase in  accuracy this substantiates the efficacy and feasibility of our  proposed approach 1   keywordsyolov8  sk  attention  nsppf  data  augmentation coordconv rdd2020 rdd2022 road damage  detection   roads are the main links which are the main channels that  connect cities in todays transport network they play an  invaluable role in facilitating the smooth and efficient  transport of people and goods however potholes stand out as  a constant and dangerous problem in the care and maintenance  of the road system the size and severity of potholes or holes  in the road surface varies they can be affected by several  factors such as unpredictable weather disturbances heavy  vehicle crashing and improper road maintenance impacts not  only threaten driver safety but also cause high costs to  highway authorities and their repairs in addition they  increase fuel consumption vehicle deterioration and  accidents which are major concerns for highway authorities  and road authorities general population there is growing  interest in using cuttingedge technology especially aiml to  solve problems caused by potholes pretrained models  particularly adept at tasks like semantic segmentation and  object detection enable swift analysis of realtime video  streams for pothole detection empowering road authorities to  proactively address defects and minimize maintenance costs   3 pothole detection utilizing the yolov8 framework  represents a critical initiative aimed at mitigating road hazards  on a global scale by harnessing the discriminative capabilities  of convolutional neural networks cnns this system  endeavors to reduce pothole occurrences through a mobile  application catering to the needs of both road authorities and  citizens its holistic design comprises various components  including a mobile app data review apis an object  recognition model for precise pothole detection and cloud  based data storage functionally the application serves dual  purposes detecting and collecting data primarily for local  highway authorities use visualizing collected data on a map  aiding maintenance facilities and residents in understanding  road conditions 5 the evolution from the yolo algorithm to  yolov8 signifies a significant leap in detection accuracy\n",
      "and speed rendering it an ideal framework for refining  pothole detection algorithms this paper aims to leverage  yolov8s capabilities to further enhance pothole detection  accuracy and efficacy by introducing enhancements such as  the nonlinear spatial pyramid poolingfast nsppf module  and the combination of coordconv and sk attention modules  the model gains improved understanding of road damage  geometry and location information 7 experimental results  validate the effectiveness of these enhancements achieving an  increased mean average precision map on rdd2020  dataset marking a significant improvement over the baseline  model this underscores the enhanced robustness and  accuracy of the proposed method in road damage detection  tasks   traditional convolutional neural network architecture  for road damage detection and classification a traditional  convolutional neural network cnn architecture for road  damage detection and classification typically consists of  several layers designed to extract relevant features from input  images of road surfaces and classify different types of  damage the architecture typically follows a sequential  structure starting with convolutional layers for feature  extraction followed by pooling layers for spatial reduction  and ending with fully connected layers for classification in  the context of road damage detection the cnn architecture  begins with a series of convolutional layers which apply  filters to the input image to extract features such as edges  textures and patterns indicative of road damage these  convolutional layers are typically followed by activation  functions to introduce nonlinearity and enhance the  networks ability to capture complex relationships within the  data  yolov5 for road damage detection there are four  versions of the singlestage object detection model yolov5  yolov5s yolov5m yolov5l and yolov5x among  them yolov5s is the smallest and fastest model with a  parameter of 70 m and a weight of 137 m 4 from the  image it can be seen that the basic composition of the  algorithm structure includes three parts the detecting layer  the bottleneck layer network and the backbone network it  has a focus standard convolution c3 and spatial pyramid  pooling as the backbone  single shot detector ssd algorithm for road damage  detection the single shot detector ssd algorithm is a  popular object detection framework that efficiently detects  objects of interest in images while achieving high accuracy  it is particularly wellsuited for realtime applications due to  its speed and effectiveness in the context of road damage  detection ssd can be applied to automatically identify and  localize various types of damage on road surfaces from  images or video footage ssd operates by dividing the input  image into a grid of default boxes at different aspect ratios  and scales these default boxes serve as anchor boxes that  represent potential object locations and sizes ssd then  predicts  bounding  boxes  and  corresponding  class  probabilities for objects within each grid cell                   a  neural network architecture design of yolov8   the neck layer the significant   modification in the  yolov8 backbone network is the replacement of c2f module  instead of c3 module 9 this c2f module has more hop layer  connectivity intermediate connection between layers  compared with c3 and the additional split signifies the  detection accuracy 9  the pafpn panet feature pyramid network layer a  pivotal component within yolov8 stands as a cornerstone  in the realm of object detection leveraging the foundational  framework of the feature pyramid network fpn it  orchestrates the construction of a multitiered hierarchy of  feature maps each endowed with distinct spatial resolutions  this strategic amalgamation of features gleaned from diverse  strata of a cnn empowers the model with the prowess to  discern objects across a spectrum of scales central to the  pafpns efficacy is the innovative  of path  aggregation this technique fosters a harmonious confluence  of features traversing disparate pathways within the network  fostering  enriched  information  flow  and  feature  representation furthermore the pafpn layer orchestrates  multiscale feature fusion expertly blending insights from  various tiers of the feature pyramid this fusion endeavor  enables the model to distill nuanced intricacies alongside  highlevel semantic context thereby honing its acumen in  object detection tasks through its adept orchestration of  feature aggregation and fusion at multiple scales the pafpn  layer engenders an ecosystem of efficient information  dissemination throughout the network this streamlined flow  of insights facilitates the samples aptitude in accurately  localizing and segmenting objects within input imagery  ultimately the pafpn layer stands as a linchpin in  yolov8s architecture furnishing it with the capabilitys  requisite for discerning objects of varying complexities  across diverse scales thus elevating its performance and  robustness in object detection endeavors   detection head was altered from the conventional  coupling head to state of the heart decoupling head 9 the  specialty of the decoupling architecture is that the position  information of the detected object will be transferred directly  without being relied on anchor   b  nsppf module coordconv module sk attention  module   within the field of remote sensing the task of path  removal presents considerable difficulties especially for  complex scenes and smallscale objects in response to these  challenges to developed a new deep learning network called  cdaunet designed to detect and outline these features with  better accuracy this network takes its structural motivation  from the basic architecture of unet introducing innovative  improvements to have integrated coordconv convolutions  in both the initial layer of the unet encoder and the final  decoder layer which facilitates more efficient processing of  the network to the network spatial information specific to  remote sensing images in addition to develop a distinct  mechanism called deep dual cross attention ddca  which aims to capture longrange injections in images an  important factor in remote sensing image analysis\n",
      "c  spatial transformer networks stns    state transform networks stns is thus far one of the most  universally applied fully learnable invariant solutions to  image transformation learned by cnns this is part of the  developing effort in development of cnns that are either  invariant or robust to image transformations stns retain the  fundamental view of a trainable module namely a spatial  transformer that applies a spatial transformation to the data in  input images or feature maps extracted by cnn before  processing if such a module learns to align images in a  canonical position it would then be possible to enable  invariant detection this kind of alignment is however  usually not possible in the transformation of cnn feature  maps and therefore stn networks cannot provide invariant  detection this is due to     1 sts perform a perfectly spatial transformation while  photo transformation usually also results in a change in  feature activation port sizes   2 the structure of image receptive fields individual  neurons are not immutable       generative adversarial networks or simply gans  have been in the limelight of artificial intelligence research  lately ganbased multiplayer zerosum games include a  discriminator and a generator both of them are trained with  the adversarial theory 5 the goals of the gans are to  approximate the underlying possible distribution of real data  samples and to generate new samples out of that distribution  though their very inception gans have found much  research interest in them due to their immensely large number  of applications related to speech and natural language  processing image and vision computing etc the purpose of  the survey paper is an assessment of the present status of the   technology of gans with a view to foreseeing the future  this paper first presents the application sectors theoretical  and implementation models and background of gans  proposal 6   the rdd 2020 road dataset also known as the road  damage detection dataset is a readily available data source  that is widely used for research and development in the field  of computer better technology particularly for challenges  related to road damage detection and assessment this dataset  is valuable for developing machine learning models and  algorithms aimed at automatically detecting and classifying  different types of road damage from images the dataset  typically contains many images captured using various  sensors eg cameras mounted on vehicles or drones these  images capture different sections of roads with multiple types  of damage such as cracks potholes patches in addition to  other surface irregularities the dataset often includes images  captured under different environmental conditions eg  different lighting weather and road surface conditions and  from diverse geographic locations this variability helps  ensure that models trained on the dataset generalize well to  realworld scenarios this ensures the variability of the  dataset     the rdd2022 road damage dataset part of crowd  based road damage detection challenge crddc2022  in the ieee bigdata cup includes approximately 50000 road  images from six different countries japan india the czech  republic norway the united states and china it features  annotations for over 60000 instances of road damage  categorized into some types longitudinal cracks  some  cracks alligator cracks and potholes and even covering some  defects this dataset is intended to support the development  of deep learning techniques for the automatic detection and  classification of road damage it offers municipalities and  highway authorities a costeffective tool for road condition  monitoring additionally computer scientists and machine  learning researchers can utilize the dataset to evaluate and  compare various algorithms in similar image based tasks  such as classification and object recognition   b data preprocessing  common image preprocessing techniques for yolo object  detection models include resizing images to a fixed size like  416x416 or 608x608 pixels to ensure consistent input  dimensions normalization of pixel values to a certain range  typically 0 1 or 1 1 aids in faster convergence during  training 1 data augmentation methods like random rotation  and translation are applied to increase the diversity of  training data improving model robustness padding or  letterboxing may be necessary to adjust input sizes and  maintain aspect ratios color space conversion like rgb to  bgr may be required based on model or framework  specifications data cleaning involves removing irrelevant or  noisy parts of images while histogram equalization enhances  contrast for improved object visibility noise reduction  techniques such as gaussian blur or median blur are used to  remove noise particularly in lowquality datasets finally  image enhancement methods like sharpening or denoising  enhance overall image quality and\n",
      "clarity these preprocessing steps are crucial for optimizing  yolo object detection models and can vary based on dataset  characteristics model architecture and task requirements   increase the diversity of the training required data by  making a model from various data aggregation techniques 3  this can help improve the robustness of your model and its  ability to generalize to different road damage scenarios  transfer learning finetuning of yolo v8 model on a  large dataset of road damage images anyone   can use pretrained models on large datasets such as coco  or imagenet and finetune them on the road damage dataset  this can help improve the performance of your model  especially if there is limited labeled data     yolov8 or you only look once version 8 is an  object detection algorithm that belongs to the yolo family  of models 2 yolov8 builds upon its predecessors  incorporating advancements in deep learning techniques to  achieve faster and more accurate object detection in images  and videos in the context of road damage detection  yolov8 can be utilized as a powerful tool for automatically  identifying and localizing various types of damage on road  surfaces from images or video footage 2     in order for yolov8 to function the feeding image is  divided into a grid boxes and for each grids objects  bounding boxes and ml class probabilities are predicted in  contrast to conventional object identification techniques that  depend on area proposal networks or sliding windows  yolov8 detects objects in a single network pass which  makes it extraordinarily quick and effective additionally  yolov8 utilizes boxes to improve detection accuracy of  different sizes and aspect ratios in road damage detection  yolov8 can be trained on annotated datasets containing  images of roads with various types of damage such as cracks  potholes patches and other surface irregularities during  inference yolov8 can accurately detect and localize road  damage in new images or video frames providing valuable  insights  for  infrastructure  maintenance  and  safety  management by automatically identifying and quantifying  road damage yolov8 enables governments transportation  agencies and road maintenance companies to prioritize repair  efforts allocate resources efficiently and ultimately enhance  road quality and safety       furthermore yolov8s speed and efficiency make it well  suited for realtime road damage detection applications such  as onboard systems in vehicles or drones 2 by integrating  yolov8 into these systems road damage can be detected  and addressed in periodic manner minimizing the risk of  casualities and optimizing road maintenance operations  overall yolov8 serves as a versatile and powerful tool for  road flaw detection leveraging arts safety deep learning  techniques to improve infrastructure management and  enhance road safety 4   e metrics  loss function there are two different steps that have been  employed in loss function evaluation of yolov8 one is  allocation strategy and the other one is loss calculation 9  allocation strategy is task aligned assignor which optimally  selects the weighted classification and regression results of  positive samples  9 which uses two hyperparameter  constants alpha and beta iouintersection over union of  the predicted box and the ground truth box will be the result  of this step with these metrics yolov8 calculates box loss  segmentation loss distribution focal loss dfl loss and  classification loss apart from loss functions map mean  average precision has been used to evaluate the performance  of the training model 2     performance evaluation values of the trained yolov8      f automation of road damage maintainance  automating the maintenance of road defects seamlessly is  paramount for ensuring the infrastructures facilitation of  transportation and logistics given their pivotal role in modern  society transportation stands as an indispensable aspect for  both the public and industries alike underscoring the  responsibility of the transport ministry to uphold safety  security and convenience by harnessing the transformative  potential of web3 and artificial intelligence ai to can  revolutionize the inspection and detection of road damage  obviating the need for laborious manual inspections  leveraging iotconnected cameras installed in school vans  college buses google earth vehicles and public transports\n",
      "to can seamlessly capture images of roads and transmit them  to cloud endpoints 9 these images are then routed to  pretrained ai models for damage detection enabling swift  identification of any anomalies upon detecting road damage  an immediate notification is dispatched to the maintenance  team facilitating prompt action to rectify the issue  moreover by opening up the platform to the public  individuals can upload images depicting transportation  related concerns these submissions undergo thorough  scrutiny and are promptly escalated to the relevant authorities  for swift resolution thereby ensuring the fulfillment of the  publics needs through this innovative fusion of web3  technology and aidriven automation to pave the way for a  safer more efficient transportation ecosystem bolstering  public trust and satisfaction while streamlining maintenance  processes for road infrastructure 8     pleasure to express our sincere gratitude to  everyone who despite not being directly connected to the  projects results contributed their skills and knowledge in a  way that considerably aided the research to extend our  special gratitude to the team members for their unshakable  dedication and camaraderie which were essential to the  projects success         1  road damage detection algorithm based on multiscale feature  extraction zhixian zhang wenhua cui ye tao and tianwei shi  2  a comparative analysis of yolov8 and yolov5 for nut thread  classification  deep learning approach sarthak patil1  gaurav dave  2  shubham urmode3  3  a comparison of yolov5 and yolov8 in the context of mobile ui  detection  burcu  selcuk0000000292006017  and  tacha  serif0000000318194926 yeditepe university atasehir 34755  turkey  4  performance comparison of yolov5 and yolov8 architectures in  human detection using aerial images indri purwita sary1  edmun  ucok armin2  safrian andromeda3  5  generative adversarial networks  and outlook kunfeng  wang member ieee chao gou yanjie duan yilun lin xinhu  zheng and feiyue wang fellow ieee  6  understanding when spatial transformer networks do not support  invariance and what to do about it lukas finnveden  ylva jansson  and tony lindeberg computational brain science lab division of  computational science and technology kth royal institute of  technology stockholm sweden  7  cdaunet a novel coordconvintegrated deep dual cross  attention mechanism for enhanced road extraction in remote  sensing imagery anchao yin 1  chao ren 12  weiting yue 1   hongjuan shao 1 and xiaoqin xue 1  8  an annotated street view image dataset for automated road damage  detection miao ren xianfeng zhang  xiaobo zhi yuanjia wei   ziyuan feng  9  a lightweight model of underwater object detection based on  yolov8n for an edge computing platform yibing fan lanyong  zhang and peng li\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  \n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, simpledialog\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import LongformerModel, LongformerTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "LEARNING_STORAGE_PATH = \"learning_data.json\"\n",
    "\n",
    "\n",
    "sbert = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "longformer = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "\n",
    "def ensureLearningStorage():\n",
    "    if not os.path.exists(LEARNING_STORAGE_PATH):\n",
    "        with open(LEARNING_STORAGE_PATH, \"w\") as f:\n",
    "            json.dump({\"documents\": []}, f, indent=4)\n",
    "\n",
    "ensureLearningStorage()\n",
    "\n",
    "\n",
    "def loadLearningData():\n",
    "    with open(LEARNING_STORAGE_PATH, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def saveLearningData(new_data):\n",
    "    with open(LEARNING_STORAGE_PATH, \"w\") as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "\n",
    "\n",
    "def cleanText(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n+', ' ', text) \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) \n",
    "    text = re.sub(r'\\b(?:introduction|abstract|conclusion|references)\\b', '', text, flags=re.IGNORECASE)  \n",
    "    return text\n",
    "\n",
    "\n",
    "def extractText(pdfPath):\n",
    "    doc = fitz.open(pdfPath)\n",
    "    return [\" \".join([b[4] for b in page.get_text(\"blocks\") if len(b[4].split()) > 5]) for page in doc]\n",
    "\n",
    "\n",
    "def splitSentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "\n",
    "def getSentenceEmbeddings(sentences):\n",
    "    sbertEmbeddings = sbert.encode(sentences)\n",
    "    \n",
    "    longformerEmbeddings = []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = longformer(**inputs)\n",
    "        longformerEmbeddings.append(outputs.last_hidden_state.mean(dim=1).numpy().flatten())\n",
    "\n",
    "    return np.hstack((sbertEmbeddings, np.array(longformerEmbeddings)))\n",
    "\n",
    "\n",
    "class HighlightSelector(gym.Env):\n",
    "    def _init_(self, scores):\n",
    "        super(HighlightSelector, self)._init_()\n",
    "        self.scores = np.array(scores)\n",
    "        self.numSentences = len(scores)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.numSentences,), dtype=np.float32)\n",
    "        self.action_space = spaces.Discrete(self.numSentences)\n",
    "\n",
    "        self.state = np.zeros(self.numSentences)\n",
    "        self.currentStep = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.zeros(self.numSentences)\n",
    "        self.currentStep = 0\n",
    "        return self.state.copy()\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = self.scores[action] if self.state[action] == 0 else -1  \n",
    "        self.state[action] = 1\n",
    "        self.currentStep += 1\n",
    "        return self.state.copy(), reward, self.currentStep >= self.numSentences, {}\n",
    "\n",
    "\n",
    "def selectSentences(sentences, scores, maxHighlights=20):\n",
    "    if len(sentences) < 2:\n",
    "        return sentences  \n",
    "\n",
    "    env = DummyVecEnv([lambda: HighlightSelector(scores)])\n",
    "    ppo = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "\n",
    "    selectedSentences = []\n",
    "    state = env.reset()\n",
    "\n",
    "    for _ in range(maxHighlights):\n",
    "        action, _ = ppo.predict(state, deterministic=True)\n",
    "        if state[0][action] == 0:\n",
    "            selectedSentences.append(sentences[action])\n",
    "        state, _, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return selectedSentences\n",
    "\n",
    "\n",
    "def applyHighlights(originalPdf, importantSentences, outputPdf):\n",
    "    doc = fitz.open(originalPdf)\n",
    "\n",
    "    for page in doc:\n",
    "        for sentence in importantSentences:\n",
    "            areas = page.search_for(sentence)\n",
    "            if not areas:\n",
    "                words = sentence.split()\n",
    "                for i in range(len(words) - 4):\n",
    "                    phrase = \" \".join(words[i:i+4])\n",
    "                    areas = page.search_for(phrase)\n",
    "                    if areas:\n",
    "                        break\n",
    "\n",
    "            for rect in areas:\n",
    "                highlight = page.add_highlight_annot(rect)\n",
    "                highlight.set_colors(stroke=(1, 1, 0))  \n",
    "                highlight.update()\n",
    "\n",
    "    doc.save(outputPdf, garbage=4, deflate=True)\n",
    "    print(f\" Highlighted PDF saved as: {outputPdf}\")\n",
    "\n",
    "# Store learnings\n",
    "def storeLearnings(pdfPath, importantSentences, scores):\n",
    "    learningData = loadLearningData()\n",
    "\n",
    "    learningEntry = {\n",
    "        \"pdf\": pdfPath,\n",
    "        \"sentences\": importantSentences,\n",
    "        \"scores\": scores.tolist()\n",
    "    }\n",
    "\n",
    "    learningData[\"documents\"].append(learningEntry)\n",
    "    saveLearningData(learningData)\n",
    "    print(\" Learning data updated!\")\n",
    "\n",
    "\n",
    "def getUserFeedback(highlighted_sentences):\n",
    "    print(\"\\nðŸ’¡ Please rate the highlighted sentences:\")\n",
    "    feedback = {}\n",
    "    for sentence in enumerate(highlighted_sentences, 1):\n",
    "        rating = simpledialog.askinteger(\"Feedback\", f\"Rate this highlight (1-5):\\n{sentence}\", minvalue=1, maxvalue=5)\n",
    "        feedback[sentence] = rating\n",
    "    return feedback\n",
    "\n",
    "\n",
    "def run():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    pdfPath = filedialog.askopenfilename(title=\"Select PDF\", filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "\n",
    "    if not pdfPath:\n",
    "        print(\" No PDF selected. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\" Selected PDF: {pdfPath}\")\n",
    "    pageTexts = extractText(pdfPath)\n",
    "    \n",
    "    allHighlights = []\n",
    "\n",
    "    for text in pageTexts:\n",
    "        text = cleanText(text)\n",
    "        sentences = splitSentences(text)\n",
    "        for sent in sentences:\n",
    "            print(sent)\n",
    "        continue\n",
    "        if not sentences:\n",
    "            continue  \n",
    "\n",
    "        embeddings = getSentenceEmbeddings(sentences)\n",
    "        scores = cosine_similarity(embeddings).mean(axis=1)\n",
    "\n",
    "        importantSentences = [sentences[i] for i in np.argsort(scores)[::-1][:20]]\n",
    "        rlSelectedSentences = selectSentences(sentences, scores, maxHighlights=20)\n",
    "        finalHighlights = list(set(importantSentences + rlSelectedSentences))\n",
    "        allHighlights.extend(finalHighlights)\n",
    "    return\n",
    "    outputPdf = os.path.splitext(pdfPath)[0] + \"_highlighted.pdf\"\n",
    "    applyHighlights(pdfPath, allHighlights, outputPdf)\n",
    "    storeLearnings(pdfPath, allHighlights, scores)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
       "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
       "      <td>Experts question if  packed out planes are put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
       "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
       "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
       "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
       "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
       "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
       "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
       "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
       "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
       "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
       "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
       "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
       "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
       "\n",
       "                                             article  \\\n",
       "0  Ever noticed how plane seats appear to be gett...   \n",
       "1  A drunk teenage boy had to be rescued by secur...   \n",
       "2  Dougie Freedman is on the verge of agreeing a ...   \n",
       "3  Liverpool target Neto is also wanted by PSG an...   \n",
       "4  Bruce Jenner will break his silence in a two-h...   \n",
       "\n",
       "                                          highlights  \n",
       "0  Experts question if  packed out planes are put...  \n",
       "1  Drunk teenage boy climbed into lion enclosure ...  \n",
       "2  Nottingham Forest are close to extending Dougi...  \n",
       "3  Fiorentina goalkeeper Neto has been linked wit...  \n",
       "4  Tell-all interview with the reality TV star, 6...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('test22.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['article'][1].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(sent_tokenize(data['article'][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(sent_tokenize(data['highlights'][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
